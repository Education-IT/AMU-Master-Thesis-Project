{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top prompts from sheet: 1-Prompt\n",
      "                    wins   score\n",
      "Reference:             9   359.0\n",
      "Concept:              12   361.0\n",
      "Info:                  8   445.0\n",
      "Information:           9   454.0\n",
      "Context:               3   467.0\n",
      "brak promptu           8   489.0\n",
      "WebContext:            0   529.0\n",
      "\"2\"                    4   545.0\n",
      "Data:                  3   548.0\n",
      "\"5\"                    3   569.0\n",
      "\"4\"                    5   609.0\n",
      "\"3\"                    5   629.0\n",
      "\"1\"                    6   656.0\n",
      "delta-Reference:       0  1308.0\n",
      "delta-Concept:         0  1310.0\n",
      "delta-Info:            0  1388.0\n",
      "delta-Information:     0  1394.0\n",
      "delta-Context:         0  1407.0\n",
      "delta-WebContext:      0  1462.0\n",
      "delta-\"2\"              0  1480.0\n",
      "delta-Data:            0  1481.0\n",
      "delta-\"5\"              0  1497.0\n",
      "delta-\"4\"              0  1537.0\n",
      "delta-\"3\"              0  1559.0\n",
      "delta-\"1\"              0  1581.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 2-Adjective\n",
      "                              wins   score\n",
      "Useful concept:                 10   426.0\n",
      "Helpful concept:                 7   531.0\n",
      "Relevant concept:                8   531.0\n",
      "Useful reference:                6   540.0\n",
      "Referencial concept:             5   585.0\n",
      "Reference:                       1   619.0\n",
      "Helpful reference:               2   629.0\n",
      "Referencial reference:           2   634.0\n",
      "Contextual concept:              6   635.0\n",
      "Concept:                         3   637.0\n",
      "Verified concept:               10   650.0\n",
      "Infomative concept:              4   661.0\n",
      "Infomative reference:            2   668.0\n",
      "Relevant reference:              4   673.0\n",
      "Contextual reference:            2   683.0\n",
      "Verified reference:              3   742.0\n",
      "delta-Useful concept:            0  1602.0\n",
      "delta-Useful reference:          0  1676.0\n",
      "delta-Relevant concept:          0  1683.0\n",
      "delta-Helpful concept:           0  1688.0\n",
      "delta-Referencial concept:       0  1739.0\n",
      "delta-Referencial reference:     0  1758.0\n",
      "delta-Contextual concept:        0  1771.0\n",
      "delta-Helpful reference:         0  1772.0\n",
      "delta-Verified concept:          0  1773.0\n",
      "delta-Infomative concept:        0  1782.0\n",
      "delta-Infomative reference:      0  1792.0\n",
      "delta-Contextual reference:      0  1796.0\n",
      "delta-Relevant reference:        0  1802.0\n",
      "delta-Verified reference:        0  1837.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 3-Separator\n",
      "                 wins  score\n",
      "brak separatora    32  184.0\n",
      "\"                  17  222.0\n",
      "*                  10  240.0\n",
      "'                   6  261.0\n",
      "#                   6  307.0\n",
      "###                 4  340.0\n",
      "Delta-\"             0  630.0\n",
      "Delta-*             0  644.0\n",
      "Delta-'             0  658.0\n",
      "Delta-#             0  699.0\n",
      "Delta-###           0  731.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 4-Contamination\n",
      "                                  wins  score\n",
      "Useful concept:                     46  118.0\n",
      "<task> useful concept:              22  139.0\n",
      "<task> benchmark useful concept:     7  186.0\n",
      "delta-<task>                         0  315.0\n",
      "delta-<task>-benchmark               0  357.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Sheets = [\"1-Prompt\", \"2-Adjective\", \"3-Separator\", \"4-Contamination\"]\n",
    "file_path = \"./Prompt.xlsx\"\n",
    "\n",
    "for sheet_name in Sheets:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    score_columns = df.columns[2:]\n",
    "\n",
    "    df[score_columns] = df[score_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    rankings = df[score_columns].rank(method=\"min\", axis=1, ascending=False)\n",
    "    column_scores = rankings.sum()\n",
    "\n",
    "    best_columns = df[score_columns].idxmax(axis=1)\n",
    "    column_wins = best_columns.value_counts()\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"wins\": column_wins,\n",
    "        \"score\": column_scores\n",
    "    }).fillna(0)\n",
    "\n",
    "    summary[\"wins\"] = summary[\"wins\"].astype(int)\n",
    "\n",
    "    summary = summary.sort_values(by=\"score\", ascending=True)\n",
    "\n",
    "    print(f\"Top prompts from sheet: {sheet_name}\")\n",
    "    print(summary)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiza dla arkusza: 1-Prompt\n",
      "Suma rankingów dla każdej kolumny:\n",
      "Reference:      362.0\n",
      "Concept:        363.0\n",
      "Info:           447.0\n",
      "Information:    456.0\n",
      "Context:        464.0\n",
      "null            489.0\n",
      "WebContext:     530.0\n",
      "Data:           541.0\n",
      "2               546.0\n",
      "5               569.0\n",
      "4               609.0\n",
      "3               629.0\n",
      "1               656.0\n",
      "dtype: float64\n",
      "\n",
      "Najlepszy prompt: Reference:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./Prompt.xlsx\"\n",
    "sheet_name = \"1-Prompt\" \n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "score_columns = df.columns[2:]\n",
    "df[score_columns] = df[score_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "rankings = df[score_columns].rank(method=\"min\", axis=1, ascending=False)\n",
    "column_scores = rankings.sum()\n",
    "sorted_scores = column_scores.sort_values()\n",
    "\n",
    "print(f\"Analiza dla arkusza: {sheet_name}\")\n",
    "print(\"Suma rankingów dla każdej kolumny:\")\n",
    "print(sorted_scores)\n",
    "\n",
    "best_prompt = sorted_scores.idxmin()\n",
    "print(f\"\\nNajlepszy prompt: {best_prompt}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
