{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top prompts from sheet: 1-Prompt\n",
      "              wins  score\n",
      "Reference:       9  362.0\n",
      "Concept:        11  363.0\n",
      "Info:            7  447.0\n",
      "Information:     8  456.0\n",
      "Context:         5  464.0\n",
      "null             8  489.0\n",
      "WebContext:      0  530.0\n",
      "Data:            4  541.0\n",
      "\"2\"              4  546.0\n",
      "\"5\"              3  569.0\n",
      "\"4\"              5  609.0\n",
      "\"3\"              5  629.0\n",
      "\"1\"              6  656.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 2-Adjective\n",
      "                        wins  score\n",
      "Useful concept:           11  413.0\n",
      "Helpful concept:           7  532.0\n",
      "Relevant concept:          8  532.0\n",
      "Useful reference:          5  541.0\n",
      "Referencial concept:       5  586.0\n",
      "Reference:                 1  620.0\n",
      "Helpful reference:         2  630.0\n",
      "Contextual concept:        6  635.0\n",
      "Referencial reference:     2  635.0\n",
      "Concept:                   3  638.0\n",
      "Verified concept:         10  651.0\n",
      "Infomative concept:        4  662.0\n",
      "Infomative reference:      2  669.0\n",
      "Relevant reference:        4  674.0\n",
      "Contextual reference:      2  684.0\n",
      "Verified reference:        3  743.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 3-Separator\n",
      "      wins  score\n",
      "std     29  196.0\n",
      "(\")     16  221.0\n",
      "(*)     11  231.0\n",
      "('')     7  258.0\n",
      "#        7  306.0\n",
      "###      5  337.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Top prompts from sheet: 4-Contamination\n",
      "                  wins  score\n",
      "std                 46  118.0\n",
      "<task>              22  139.0\n",
      "<task> benchmark     7  186.0\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Sheets = [\"1-Prompt\", \"2-Adjective\", \"3-Separator\", \"4-Contamination\"]\n",
    "file_path = \"./Prompt.xlsx\"\n",
    "\n",
    "for sheet_name in Sheets:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "    score_columns = df.columns[2:]\n",
    "\n",
    "    df[score_columns] = df[score_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    rankings = df[score_columns].rank(method=\"min\", axis=1, ascending=False)\n",
    "    column_scores = rankings.sum()\n",
    "\n",
    "    best_columns = df[score_columns].idxmax(axis=1)\n",
    "    column_wins = best_columns.value_counts()\n",
    "\n",
    "    summary = pd.DataFrame({\n",
    "        \"wins\": column_wins,\n",
    "        \"score\": column_scores\n",
    "    }).fillna(0)\n",
    "\n",
    "    summary[\"wins\"] = summary[\"wins\"].astype(int)\n",
    "\n",
    "    summary = summary.sort_values(by=\"score\", ascending=True)\n",
    "\n",
    "    print(f\"Top prompts from sheet: {sheet_name}\")\n",
    "    print(summary)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiza dla arkusza: 1-Prompt\n",
      "Suma rankingów dla każdej kolumny:\n",
      "Reference:      362.0\n",
      "Concept:        363.0\n",
      "Info:           447.0\n",
      "Information:    456.0\n",
      "Context:        464.0\n",
      "null            489.0\n",
      "WebContext:     530.0\n",
      "Data:           541.0\n",
      "2               546.0\n",
      "5               569.0\n",
      "4               609.0\n",
      "3               629.0\n",
      "1               656.0\n",
      "dtype: float64\n",
      "\n",
      "Najlepszy prompt: Reference:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"./Prompt.xlsx\"\n",
    "sheet_name = \"1-Prompt\" \n",
    "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "\n",
    "score_columns = df.columns[2:]\n",
    "df[score_columns] = df[score_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "rankings = df[score_columns].rank(method=\"min\", axis=1, ascending=False)\n",
    "column_scores = rankings.sum()\n",
    "sorted_scores = column_scores.sort_values()\n",
    "\n",
    "print(f\"Analiza dla arkusza: {sheet_name}\")\n",
    "print(\"Suma rankingów dla każdej kolumny:\")\n",
    "print(sorted_scores)\n",
    "\n",
    "best_prompt = sorted_scores.idxmin()\n",
    "print(f\"\\nNajlepszy prompt: {best_prompt}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
