{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of the Decontamination Algorithm:\n",
    "\n",
    "https://www.statystyczny.pl/macierz-bledow-raport-dokladnosc-czulosc-precyzja/\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------------+---------------------+-------------------+-----------------------------------+------------+------------+\n",
      "|   Version | Task     |   Recall (TPR) |   Specificity (TNR) |   Precision (PPV) |   Negative Predictive Value (NPV) |   Accuracy |   F1 Score |\n",
      "+===========+==========+================+=====================+===================+===================================+============+============+\n",
      "|         1 | ARC-Easy |        95.5367 |             51.2035 |           80.1248 |                           84.7826 |    81.0443 |    87.1546 |\n",
      "+-----------+----------+----------------+---------------------+-------------------+-----------------------------------+------------+------------+\n",
      "|         2 | ARC      |        96.5299 |             74.0365 |           92.5904 |                           86.3905 |    91.3721 |    94.5191 |\n",
      "+-----------+----------+----------------+---------------------+-------------------+-----------------------------------+------------+------------+\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from tabulate import tabulate\n",
    "\n",
    "def calculate(TP, TN, FP, FN, version, task):\n",
    "    metrics = {\n",
    "        \"Version\": version,\n",
    "        \"Task\": task,\n",
    "        \"Recall (TPR)\": TP / (TP + FN) * 100,\n",
    "        \"Specificity (TNR)\": TN / (TN + FP) * 100,\n",
    "        \"Precision (PPV)\": TP / (TP + FP) * 100,\n",
    "        \"Negative Predictive Value (NPV)\": TN / (TN + FN) * 100,\n",
    "        \"Accuracy\": (TP + TN) / (TP + TN + FP + FN) * 100,\n",
    "        \"F1 Score\": 2 * (TP / (TP + FP) * 100 * TP / (TP + FN) * 100) / (TP / (TP + FP) * 100 + TP / (TP + FN) * 100)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# Oblicz metryki\n",
    "metrics0 = calculate(1798, 468, 446, 84, '1.0', 'ARC-Easy')\n",
    "metrics1 = calculate(3199, 730, 256,115,'2.0', 'ARC')\n",
    "#metrics1 = calculate(1019, 388, 117, 31, '2.0', 'ARC-Challenge')\n",
    "#metrics2 = calculate(2180, 342, 139, 84, '2.0', 'ARC-Easy')\n",
    "\n",
    "#metrics_avg = {key: (metrics1[key] + metrics2[key]) / 2 if key not in ['Version', 'Task'] else 'Avg-New' for key in metrics1}\n",
    "#metrics_diff = {key: round(metrics_avg[key] - metrics0[key], 2) if key not in ['Version', 'Task'] else 'Improvement' for key in metrics0}\n",
    "\n",
    "# Lista słowników do zapisania\n",
    "all_metrics = [metrics0, metrics1]#, metrics2, metrics_avg, metrics_diff]\n",
    "\n",
    "# Zapis do CSV\n",
    "with open('metrics_output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=all_metrics[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_metrics)\n",
    "\n",
    "# Wypisz tabelę\n",
    "print(tabulate(all_metrics, headers=\"keys\", tablefmt=\"grid\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
